{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Labrakates","text":"<p>Labrakates is a project to run InstructLab in Kubernetes using Tekton Pipelines, enabling users to fine-tune large language models with their own repository of knowledge or skills within their GPU-enabled Kubernetes clusters.</p> <p>The name is roughly inspired by the InstructLab labrador combined with the way some people pronounce the Kubernetes abbreviation \"k8s\" as \"kates\" / \"keights\".</p>"},{"location":"#overview","title":"Overview","text":"<p>InstructLab has two distinct steps that are required for fine-tuning a large language model - synthetic data generation and training.</p>"},{"location":"#synthetic-data-generation-pipeline","title":"Synthetic Data Generation Pipeline","text":"<p>This generate pipeline generates synthetic question and answer pairs, which will potentially be used later for training a student model, from an InstructLab taxonomy repository. The expected use is that you have your own taxonomy repository containing the knowledge or skills you want to teach your student model. An example taxonomy repositoy is maintained at konflux-taxonomy.</p> <p>The output of the generate pipeline is a set of json training data files, stored in S3-compatible object storage of your choice.</p>"},{"location":"#training-pipeline","title":"Training Pipeline","text":"<p>The train pipeline takes an input set of generated data and fine-tunes the student model of your choice, using either a full fine-tuning or LoRA methods (to save on hardware resources at the expense of some accuracy).</p> <p>The output of the train pipeline is a set of model files (or LoRA adapter weights) in HuggingFace repository format, stored in S3-compatible object storage of your choice.</p>"}]}